---
title: "`qens`: Quantile Ensembles"
output: rmarkdown::html_vignette
vignette: >
  %\VignetteIndexEntry{`qens`: Quantile Ensembles}
  %\VignetteEngine{knitr::rmarkdown}
  %\VignetteEncoding{UTF-8}
---

```{r, include = FALSE}
knitr::opts_chunk$set(
  collapse = TRUE,
  comment = "#>"
)
```

# Methods description

Let $i = 1, \ldots, N$ index forecast tasks; for example, each $i$ may correspond to a combination of location, forecast date, and target for which we want to produce forecasts. For each forecast task, we have predictive distributions from different models indexed by $m = 1, \ldots, M$, and each such distribution is represented by a collection of $K$ predictive quantiles at probability levels $\tau_1, \ldots, \tau_K$. Denote the predictive quantile for case $i$ from model $m$ at quantile level $\tau_k$ by $q_{i,k,m}$. For now, we assume none of these predictive quantiles are missing; we describe a strategy for handling missing predictions by renormalizing model weights below.

Our goal is to obtain an ensemble forecast at each probability level $\tau_k$ by combining the predictive quantiles from the component models at that probability level. We will do this by calculating a mean or median of the component forecasts. We allow for the possibility of assigning each model $m$ an estimated weight $w_{k,m}$. We require that these weights are non-negative and sum to one at each quantile level. The weights are held fixed for all cases $i$, but in general may be allowed to vary across quantile levels indexed by $k$. However, we may find it helpful to be able to share parameters within some pre-specified groups of quantile levels.

If a weighted mean is used, the ensemble's predictive quantile for given indices $i$ and $k$ can be calculated as $q_{i, k} = \sum_{m=1}^M w_{k,m} q_{i,k,m}$.

The weighted median is defined to be $\inf\left\{q \in \mathbb{R}: \sum_{m = 1}^M w^m_s 1_{(-\infty, q]}(q^{m}_{l,s,t,k}) \geq 0.5\right\}$, where $1_A(x)$ is the indicator function that takes the value $1$ if $x \in A$ and $0$ otherwise. Informally, this is the smallest value for which the cumulative weight assigned to the model predictions is at least 0.5. It can be helpful to conceptualize this as the median of a discrete distribution with weighted point masses at the component forecaster predictions.

A challenge is that the weighted median is not differentiable in the model weights, which makes weight estimation difficult. To facilitate weight estimation via gradient-based optimization algorithms, rather than using the median of the discrete distribution corresponding to the weighted component forecaster predictions, we use the median of a smoothed version of that distribution obtained via kernel density estimation.

To calculate the weighted median of the predictive quantiles for given indices $i$ and $k$ (corresponding to a specified location, forecast date, target, and quantile level), we take a two-step approach:

1. We use a weighted kernel density estimate with kernel function $g$ to obtain a smoothed estimate of the the distribution of values for the predictive quantile $q$ across different component forecasters, with pdf $f(q) = \sum_{m=1}^M w_{k,m} g_{\theta_{i,k,m}}(q,q_{i,k,m})$ and corresponding cdf $F(q)$.
2. We calculate the weighted median by inverting this cdf at the probability level 0.5: $q_{i,k} = F^{-1}(0.5)$.

We use an adaptive rectangular kernel function $g$, which corresponds to placing a uniform distribution centered at the prediction from each component forecaster, scaling it down by its weight, and summing across component forecasters to get the pdf or cdf.  Using a rectangular kernel is helpful because then the cdf is piecewise linear, which is fast and easy to invert; this is important because the estimation procedure requires that we do this inversion many times. We set the half-width of the kernel function used for model $m$ for a given forecast task $i$ and probability level $k$ to be twice the distance from the component forecaster's prediction to the nearest prediction made by another model. This adaptivity allows the range of values over which each forecaster's weight to be responsive to the local density of model predictions.

We illustrate this process in a simple example for combining predictive quantiles from three models for a single case $i$ and quantile level $k$.  In this example, we suppose that model 1 had predictive quantile 2 and is given weight 0.2, model 2 had predictive quantile 4 and is given weight 0.7, and model 3 had predictive quantile 8 and is given weight 0.1.  Panel (a) shows a "probability mass function" view of the situation, where each predictive quantile is given the corresponding weight and a rectangular kernel density estimate is used to obtain a distribution over this quantile value.  The estimated weighted median (i.e., the ensemble prediction for case $i$ and quantile level $k$) is illustrated with a vertical dashed line; visually, this divides the area under the corresponding density estimate in half. Panel (b) shows the cumulative distribution functions corresponding to the kernel density estimates in panel (a).  The weighted median is obtained by inverting this CDF at probability level 0.5.

```{r, echo = FALSE, message=FALSE, warning=FALSE, fig.width=8, fig.height=8}
library(tidyverse)
library(gridExtra)
lower_lim <- -5
upper_lim <- 15
pred_quantiles <- data.frame(
  model = letters[1:3],
  quantile = c(2, 4, 8),
  weight = c(0.2, 0.7, 0.1),
  cum_weight = cumsum(c(0.2, 0.7, 0.1)),
  zeros = 0
)

# KDE bandwidth is the half-width of the kernel centered at each prediction,
# calculated as the distance to the nearest prediction from another model
kde_bw <- c(2, 2, 4)

rectangle_width <- 2 * kde_bw

calc_cdf_value <- function(x, q, w, rectangle_width) {
  if (length(q) != length(w)) {
    stop("lengths of q and w must be equal")
  }
  result <- rep(0, length(x))
  for (i in seq_along(q)) {
    result <- result + dplyr::case_when(
        x < q[i] - rectangle_width[i] / 2 ~ 0,
        ((x >= q[i] - rectangle_width[i] / 2) &
            (x <= q[i] + rectangle_width[i] / 2)) ~
          w[i] * (x - (q[i] - rectangle_width[i] / 2)) * (1 / rectangle_width[i]),
        x > q[i] + rectangle_width[i] / 2 ~ w[i]
      )
  }
  return(result)
}

calc_inverse_cdf <- function(p, q, w, rectangle_width) {
  slope_changepoints <- sort(c(q - rectangle_width / 2, q + rectangle_width / 2))
  changepoint_cdf_values <- calc_cdf_value(
    x = slope_changepoints,
    q = q, w = w, rectangle_width = rectangle_width
  )
  purrr::map_dbl(p,
    function(one_p) {
      start_ind <- max(which(changepoint_cdf_values < one_p))
      segment_slope <- diff(changepoint_cdf_values[c(start_ind + 1, start_ind)]) /
        diff(slope_changepoints[c(start_ind + 1, start_ind)])
      return(
        (one_p - changepoint_cdf_values[start_ind] +
          segment_slope * slope_changepoints[start_ind]) /
          segment_slope
      )
    }
  )
}
ensemble_quantile <- calc_inverse_cdf(
  p = 0.5,
  q = pred_quantiles$quantile,
  w = pred_quantiles$weight,
  rectangle_width = rectangle_width)

ensemble_quantile_to_plot <- data.frame(
    x = c(lower_lim, ensemble_quantile, ensemble_quantile),
    y = c(0.5, 0.5, 0),
    method = "unweighted_bw"
)

xs <- seq(from = lower_lim, to = upper_lim, length = 1001)

implied_pdf_cdf <- data.frame(
    x = xs,
    pdf = pred_quantiles$weight[1] / rectangle_width[1] *
      ((xs >= pred_quantiles$quantile[1] - rectangle_width[1]/2) & (xs <= pred_quantiles$quantile[1] + rectangle_width[1]/2)) +
      pred_quantiles$weight[2] / rectangle_width[2] *
      ((xs >= pred_quantiles$quantile[2] - rectangle_width[2]/2) & (xs <= pred_quantiles$quantile[2] + rectangle_width[2]/2)) +
      pred_quantiles$weight[3] / rectangle_width[3] *
      ((xs >= pred_quantiles$quantile[3] - rectangle_width[3]/2) & (xs <= pred_quantiles$quantile[3] + rectangle_width[3]/2)),
    cdf = calc_cdf_value(x = xs, q = pred_quantiles$quantile, pred_quantiles$weight, rectangle_width)
)

p1 <- ggplot(data = pred_quantiles) +
  geom_point(mapping = aes(x = quantile, y = weight)) +
  geom_segment(mapping = aes(x = quantile, y = zeros, xend = quantile, yend = weight)) +
  geom_vline(
    data = ensemble_quantile_to_plot %>% dplyr::filter(x != 0),
    mapping = aes(xintercept = x), linetype = 2) +
  geom_line(data = implied_pdf_cdf, mapping = aes(x = x, y = pdf)) +
  scale_x_continuous(
    breaks = seq(from = lower_lim, to = upper_lim, by = 2),
    limits = c(lower_lim, upper_lim),
    expand = c(0, 0)) +
  ylim(0, 1) +
  ggtitle("   (a) weighted PMF view") +
  theme_bw()

p2 <- ggplot(data = pred_quantiles) +
#  geom_point(mapping = aes(x = quantile, y = cum_weight)) +
#  geom_segment(mapping = aes(x = cdf_start_x, y = cdf_start_y, xend = quantile, yend = cum_weight)) +
  geom_line(
    data = ensemble_quantile_to_plot,
    mapping = aes(x = x, y = y),
    linetype = 2) +
  geom_line(
    data = implied_pdf_cdf,
    mapping = aes(x = x, y = cdf),
  ) +
  scale_x_continuous(
    breaks = seq(from = lower_lim, to = upper_lim, by = 2),
    limits = c(lower_lim, upper_lim),
    expand = c(0, 0)) +
#  ylim(0, 1) +
  ggtitle("   (b) weighted CDF view") +
  theme_bw()
grid.arrange(p1, p2)
```

### Model estimation

Given an observed value $y_i$, we measure the quality of the ensemble prediction at quantile level $\tau_k \in (0, 1)$ by the pinball loss:

$$L(\mathbf{w}; y_i) = \left\{ \mathbf{1}(y_i < q_{i,k}) - \tau_k \right\} \cdot (q_{i,k} - y_i),$$
where on the right hand side, $q_{i,k}$ is the ensemble forecast, obtained as the weighted mean or median through the procedure outlined above. Note that this weighted ensemble prediction depends on the model weights vector $\mathbf{w}$.  If we have many observations $i = 1, \ldots, N$ and probability levels $k = 1, \ldots, K$, we calculate the overall loss as the average loss across these predictions.

We use a gradient-based optimization procedure to estimate the weights $\mathbf{w}$ by minimizing this average loss over some training set forecasts. Estimation is implemented in tensorflow in the Python module `qens`.

# Example application

```{r setup}
library(readr)
library(dplyr)
library(purrr)
library(ggplot2)

library(reticulate)

# Note: the reticulate command below is specific to Evan's computer.
# Is there a better/more generic way to set this up?
reticulate::use_python("/usr/local/bin/python3")

library(qens)
```

First, we'll load in some sample forecasts and observed target data for weekly incident influenza hospitalizations in the US that are provided by the package. The forecast data were produced by a collection of minor variations on a baseline forecasting model based on a local level or local trend model using different settings for whether the model works with daily or weekly data and whether or not a square root data transformation is applied. The observed target data come from the HHS Protect system for collecting data on admissions to hospitals in the U.S. where the patient has influenza.

```{r}
forecasts_path <- system.file("extdata/forecast_data", package = "qens")
models <- list.files(forecasts_path)
forecasts <- purrr::map_dfr(
    models,
    function(model) {
        model_path <- file.path(forecasts_path, model)
        model_files <- list.files(model_path, full.names = TRUE)
        purrr::map_dfr(model_files, readr::read_csv,
                       col_types = cols(
                           forecast_date = col_date(format = ""),
                           target = col_character(),
                           target_end_date = col_date(format = ""),
                           location = col_character(),
                           type = col_character(),
                           quantile = col_double(),
                           value = col_double()),
                       progress = FALSE) %>%
            dplyr::filter(type == "quantile") %>%
            dplyr::mutate(model = model)
    }
)
head(forecasts)
```

We split the component model forecasts into a training set that will be used for estimating model weights, and a set of forecasts at the ``current time", which will be used to create prospective forecasts.

```{r}
unique(forecasts$forecast_date)
train_forecasts <- forecasts %>%
    dplyr::filter(forecast_date < "2022-05-30")
current_forecasts <- forecasts %>%
    dplyr::filter(forecast_date == "2022-05-30")
```

We also load the data that are used as a forecast target.

```{r}
flu_hosps <-  readr::read_csv(
    system.file("extdata/target_data/flu_hosps.csv", package = "qens"),
    col_types = cols(
        location = col_character(),
        date = col_date(format = ""),
        value = col_double()
    )) %>%
    dplyr::filter(date >= "2022-02-01", date <= "2022-09-01")
head(flu_hosps)
```

We plot the training set forecasts and the forecasts for the current date for the national level only:
```{r, fig.width=8, fig.height=12}
plot_forecasts <- function(forecasts, target_data) {
    plot_forecasts <- forecasts %>%
        dplyr::filter(location == "US") %>%
        dplyr::filter(as.character(quantile) %in% c("0.025", "0.5", "0.975")) %>%
        tidyr::pivot_wider(names_from = quantile, values_from = value)
    ggplot() +
        geom_line(
            mapping = aes(x = target_end_date, y = `0.5`,
                          group = paste0(model, forecast_date)),
            color = "cornflowerblue",
            data = plot_forecasts
        ) +
        geom_ribbon(
            mapping = aes(x = target_end_date, ymin = `0.025`, ymax = `0.975`,
                          group = paste0(model, forecast_date)),
            fill = "cornflowerblue",
            alpha = 0.3,
            data = plot_forecasts
        ) +
        geom_line(
            mapping = aes(x = date, y = value),
            data = target_data %>% dplyr::filter(location == "US")
        ) +
        facet_wrap( ~ model, ncol = 2) +
        theme_bw() +
        xlab("Date") +
        ylab("Weekly incident flu hospitalizations")
}

plot_forecasts(forecasts = train_forecasts, target_data = flu_hosps)
```

We now fit a weighted mean quantile ensemble model, estimating the weights based on the training set forecasts.

```{r}
qens_fit <- qens(predictions = train_forecasts,
                 y = flu_hosps %>% dplyr::rename(target_end_date = date),
                 model_id_vars = "model",
                 task_id_vars = c("forecast_date", "target_end_date", "location"),
                 tau_var = "quantile",
                 q_var = "value",
                 combine_method = "mean",
                 weighted = TRUE)
```

It's a good idea to plot the trace of the loss function during the course of the optimization routine for parameter estimation. This should stabilize around a low value. If it has not stabilized, estimation should be run with more optimization iterations.
```{r, fig.width=8, fig.height=6}
plot(qens_fit$loss_trace, type = "l")
```

We can inspect the component model weights, which are stored in the `weights` entry of the model fit object.
```{r}
# the weights object is matrix with one row for each model and
# one column for each quantile level
qens_fit$weights

# in this case, the weights were shared across quantile levels.
# we can match up the weights to models using the `model_id` property
# of the model fit
model_weights <- qens_fit$model_id %>%
    dplyr::mutate(weight = qens_fit$weights[1, ])
model_weights
```

We can now obtain predictions for the current time point:
```{r}
ensemble_predictions <- predict(qens_fit, current_forecasts, sort = TRUE) %>%
    dplyr::mutate(model = "weighted mean ensemble")
ensemble_predictions
```

In this case, we could have obtained the same predictions directly as a weighted mean of the predictions:
```{r}
direct_ensemble_predictions <- current_forecasts %>%
    dplyr::left_join(model_weights, by = "model") %>%
    dplyr::group_by(forecast_date, target_end_date, location, quantile) %>%
    dplyr::summarize(value = weighted.mean(value, w = weight),
                     .groups = "drop") %>%
    dplyr::mutate(model = "weighted mean ensemble")
direct_ensemble_predictions
```

We confirm here that these predictions agree up to numerical errors (note that the calculations in the python implementation are done in 32 bits and the calculations in R are done in 64 bits, so some mild discrepancy is expected).
```{r}
ensemble_predictions %>%
    dplyr::left_join(direct_ensemble_predictions,
                     by = c("forecast_date", "target_end_date",
                            "location", "quantile", "model")) %>%
    dplyr::mutate(diff = abs(value.x - value.y)) %>%
    dplyr::pull(diff) %>%
    max()
```

We plot these "current date" ensemble forecasts to confirm that they look reasonable:

```{r, fig.width=8, fig.height=6}
plot_forecasts(forecasts = ensemble_predictions, target_data = flu_hosps)
```
